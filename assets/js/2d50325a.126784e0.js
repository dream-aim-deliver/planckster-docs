"use strict";(self.webpackChunkplanckster_docs=self.webpackChunkplanckster_docs||[]).push([[4511],{9535:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>r,contentTitle:()=>s,default:()=>u,frontMatter:()=>o,metadata:()=>d,toc:()=>l});var n=a(4848),i=a(8453);const o={sidebar_label:"Analyzing Scraped Data",sidebar_position:3},s="Analyzing Scraped Data with Kubeflow Notebooks",d={id:"guides/kubeflow/analysing-scraped-data",title:"Analyzing Scraped Data with Kubeflow Notebooks",description:"First, connect to kernel-planckster:",source:"@site/docs/guides/kubeflow/analysing-scraped-data.md",sourceDirName:"guides/kubeflow",slug:"/guides/kubeflow/analysing-scraped-data",permalink:"/planckster-docs/docs/guides/kubeflow/analysing-scraped-data",draft:!1,unlisted:!1,editUrl:"https://github.com/dream-aim-deliver/planckster-docs/edit/main/docs/guides/kubeflow/analysing-scraped-data.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_label:"Analyzing Scraped Data",sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Run Kubeflow Pipelines",permalink:"/planckster-docs/docs/guides/kubeflow/running-kubeflow-pipelines"},next:{title:"Custom Pipelines",permalink:"/planckster-docs/docs/guides/kubeflow/custom-pipelines"}},r={},l=[{value:"First, connect to kernel-planckster:",id:"first-connect-to-kernel-planckster",level:2},{value:"Verify the existence of scraped data:",id:"verify-the-existence-of-scraped-data",level:4},{value:"There should exist an output that looks like the following:",id:"there-should-exist-an-output-that-looks-like-the-following",level:4},{value:"Note the mix of scraped and augmented data that is pulled.",id:"note-the-mix-of-scraped-and-augmented-data-that-is-pulled",level:5},{value:"Download all of the data sources deemed relevant to a local folder in the Kubeflow Notebook",id:"download-all-of-the-data-sources-deemed-relevant-to-a-local-folder-in-the-kubeflow-notebook",level:4},{value:"Where <code>download_source_if_relevant</code> is a function that calls:",id:"where-download_source_if_relevant-is-a-function-that-calls",level:4},{value:"Or, use the utility functions in <code>scraped_data_repository.py</code> that take care of file naming, formatting, and saving:",id:"or-use-the-utility-functions-in-scraped_data_repositorypy-that-take-care-of-file-naming-formatting-and-saving",level:4},{value:"After saving all relevant data, perform the desired vizualizations:",id:"after-saving-all-relevant-data-perform-the-desired-vizualizations",level:2},{value:"Note: visualizations require having <em>matched</em> satellite and social media data. This type of augmentation is usually performed by an <strong>Augmentation Repository</strong>, but in case it hasn&#39;t, one can use the following code:",id:"note-visualizations-require-having-matched-satellite-and-social-media-data-this-type-of-augmentation-is-usually-performed-by-an-augmentation-repository-but-in-case-it-hasnt-one-can-use-the-following-code",level:4},{value:"Clearly, tweets that are relevant to a particular disaster and ouccur on the same day as disasters detected by sattelite images are matched and the locations of both types of data can be compared and analyzed.",id:"clearly-tweets-that-are-relevant-to-a-particular-disaster-and-ouccur-on-the-same-day-as-disasters-detected-by-sattelite-images-are-matched-and-the-locations-of-both-types-of-data-can-be-compared-and-analyzed",level:5},{value:"Analyze the output using leafmap:",id:"analyze-the-output-using-leafmap",level:3},{value:"Load the true-color image from our sentinel dataset",id:"load-the-true-color-image-from-our-sentinel-dataset",level:4},{value:"Create the interactive leafmap:",id:"create-the-interactive-leafmap",level:4},{value:"Overlay the augmented social media data and disaster events",id:"overlay-the-augmented-social-media-data-and-disaster-events",level:4},{value:"The output should be interactive and have dynamic overlays:",id:"the-output-should-be-interactive-and-have-dynamic-overlays",level:4}];function c(e){const t={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",h5:"h5",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.h1,{id:"analyzing-scraped-data-with-kubeflow-notebooks",children:"Analyzing Scraped Data with Kubeflow Notebooks"}),"\n",(0,n.jsx)(t.h2,{id:"first-connect-to-kernel-planckster",children:"First, connect to kernel-planckster:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:"kernel_planckster, protocol, file_repository = setup(\n    job_id=job_id,\n    logger=logger,\n)\n"})}),"\n",(0,n.jsx)(t.h4,{id:"verify-the-existence-of-scraped-data",children:"Verify the existence of scraped data:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:"source_list = kernel_planckster.list_all_source_data()\n"})}),"\n",(0,n.jsx)(t.h4,{id:"there-should-exist-an-output-that-looks-like-the-following",children:"There should exist an output that looks like the following:"}),"\n",(0,n.jsx)(t.h5,{id:"note-the-mix-of-scraped-and-augmented-data-that-is-pulled",children:"Note the mix of scraped and augmented data that is pulled."}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:"[\n\n{'created_at': '2024-04-14T23:59:19.083454',\n  'updated_at': '2024-04-14T23:59:19.083457',\n  'deleted': False,\n  'deleted_at': None,\n  'id': 1,\n  'name': '2023_08_08__2023_08_09',\n  'relative_path': 'sentinel/test/1/true_color/2023_08_08__2023_08_09.png',\n  'type': 'png',\n  'protocol': 's3',\n  'status': 'available'\n},\n  \n{\n  \"created_at\": \"2024-04-15T04:35:20.736662\",\n  \"updated_at\": \"2024-04-15T04:35:20.736667\",\n  \"deleted\": false,\n  \"deleted_at\": null,\n  \"id\": 130,\n  \"name\": \"2023_August_23\",\n  \"relative_path\": \"augmented/by_date/2023_August_23.json\",\n  \"type\": \"json\",\n  \"protocol\": \"s3\",\n  \"status\": \"available\"\n}\n\n...\n\n}\n\n"})}),"\n",(0,n.jsx)(t.h2,{id:""}),"\n",(0,n.jsx)(t.h4,{id:"download-all-of-the-data-sources-deemed-relevant-to-a-local-folder-in-the-kubeflow-notebook",children:"Download all of the data sources deemed relevant to a local folder in the Kubeflow Notebook"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:'work_dir = "./.tmp"\nfor source in source_list:\n    download_source_if_relevant(source, job_id, tracer_id, scraped_data_repository, work_dir)\n\n'})}),"\n",(0,n.jsxs)(t.h4,{id:"where-download_source_if_relevant-is-a-function-that-calls",children:["Where ",(0,n.jsx)(t.code,{children:"download_source_if_relevant"})," is a function that calls:"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:'signed_url = kernel_planckster.download_from_signed_url(source) \nfile_repository.public_download(signed_url=signed_url, file_path="./LOCAL_DIRECTORY/some_file_name.format")\n\n'})}),"\n",(0,n.jsxs)(t.h4,{id:"or-use-the-utility-functions-in-scraped_data_repositorypy-that-take-care-of-file-naming-formatting-and-saving",children:["Or, use the utility functions in ",(0,n.jsx)(t.code,{children:"scraped_data_repository.py"})," that take care of file naming, formatting, and saving:"]}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.code,{children:"scraped_data_repository.download_img(source, job_id, path)"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.code,{children:"scraped_data_repository.download_json(source, job_id, path)"})}),"\n",(0,n.jsx)(t.li,{children:"etc."}),"\n"]}),"\n",(0,n.jsx)(t.h2,{id:"after-saving-all-relevant-data-perform-the-desired-vizualizations",children:"After saving all relevant data, perform the desired vizualizations:"}),"\n",(0,n.jsxs)(t.h4,{id:"note-visualizations-require-having-matched-satellite-and-social-media-data-this-type-of-augmentation-is-usually-performed-by-an-augmentation-repository-but-in-case-it-hasnt-one-can-use-the-following-code",children:["Note: visualizations require having ",(0,n.jsx)(t.em,{children:"matched"})," satellite and social media data. This type of augmentation is usually performed by an ",(0,n.jsx)(t.strong,{children:"Augmentation Repository"}),", but in case it hasn't, one can use the following code:"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:"# load tweets (or any kind of scraped social media) data that is relevant to the particular usecase (wildfires/disaster)\n\ntwitter_df = pd.read_json(f'{work_dir}/twitter_augment/data.json', orient=\"index\")\ntelegram_df = pd.read_json(f'{work_dir}/telegram_augment/data.json', orient=\"index\")\nsentinel_dir = os.path.join(work_dir, \"wildfire_coords\")\n    \n# load wildfire (or any kind of disaster) data\nfor wildifre_coords_json_file_path in os.listdir(sentinel_dir):\n    data = []\n    sentinel_df= pd.read_json(os.path.join(sentinel_dir,wildifre_coords_json_file_path), orient=\"index\")\n    for index, row in sentinel_df.iloc[0:].iterrows():\n        lattitude = row['latitude']\n        longitude = row['longitude']\n        status = row['status']\n                                                    #title tweet location\n        data.append([status, lattitude, longitude, \"n/a\", \"n/a\", \"n/a\" ])\n\n\n# perform matching of satellite image disaster dates with tweets\nunderscore_date=wildifre_coords_json_file_path[:wildifre_coords_json_file_path.index(\"__\")]\n    split_date = underscore_date.split(\"_\")\n    sat_image_year = split_date[0]; sat_image_month = key[split_date[1]]; sat_image_day = split_date[2]\n    \n    \n    matches_found_twitter = 0\n    for index, row in twitter_df.iloc[0:].iterrows():\n        tweet_title = row['Title']\n        tweet_tweet = row['Tweet']\n        tweet_location = row['Extracted_Location']\n        tweet_latitude = row['Resolved_Latitude']\n        tweet_longitude = row['Resolved_Longitude']\n        tweet_month = row['Month']\n        tweet_day = row['Day']\n        tweet_year = row['Year']\n        tweet_disaster_type = row['Disaster_Type']\n\n        # match satellite image dates with tweet dates\n        if(int(sat_image_year) == int(tweet_year) and sat_image_month == tweet_month and int(sat_image_day) == int(tweet_day)):\n            matches_found_twitter += 1\n            # save the data\n            data.append([f\"tweet about {tweet_disaster_type}\", tweet_latitude, tweet_longitude, tweet_title, tweet_tweet, tweet_location ])\n        \n\n"})}),"\n",(0,n.jsx)(t.h5,{id:"clearly-tweets-that-are-relevant-to-a-particular-disaster-and-ouccur-on-the-same-day-as-disasters-detected-by-sattelite-images-are-matched-and-the-locations-of-both-types-of-data-can-be-compared-and-analyzed",children:"Clearly, tweets that are relevant to a particular disaster and ouccur on the same day as disasters detected by sattelite images are matched and the locations of both types of data can be compared and analyzed."}),"\n",(0,n.jsx)(t.h3,{id:"analyze-the-output-using-leafmap",children:"Analyze the output using leafmap:"}),"\n",(0,n.jsx)(t.h4,{id:"load-the-true-color-image-from-our-sentinel-dataset",children:"Load the true-color image from our sentinel dataset"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:'from pystac_client import Client\n\nclient = Client.open("https://planetarycomputer.microsoft.com/api/stac/v1")\n\nsearch = client.search(\n    max_items=10,\n    collections=[\'sentinel-2-l2a\'],\n    bbox=[-156.708984, 20.759645, -156.299744, 20.955027],\n    datetime="2023-08-08/2023-08-25",\n)\nitems = search.item_collection()\nfor item in items:\n    print(item.id)\n\n'})}),"\n",(0,n.jsx)(t.h4,{id:"create-the-interactive-leafmap",children:"Create the interactive leafmap:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:'import leafmap.foliumap as leafmap #choose one of 6 plotting backends\n\nm = leafmap.Map()\nm.add_stac_layer(\n    collection="sentinel-2-l2a",\n    item = items[0].id, #choose the latest one to display\n    assets=["B04", "B03", "B02"],\n)\n# load the map in jupyter:\nm\n\n'})}),"\n",(0,n.jsx)(t.h4,{id:"overlay-the-augmented-social-media-data-and-disaster-events",children:"Overlay the augmented social media data and disaster events"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:"\nwork_dir = './.tmp'  #  define your work directory here\nbounding_box = (-156.708984,20.759645,-156.299744,20.955027) #set coords as well\nimport os\nimport pandas as pd\nfrom folium.features import DivIcon\n\nfor file_path in os.listdir(os.path.join(work_dir, \"by_date\")):\n    if file_path.endswith('.json'):  # check to ensure only json files are processed\n        df = pd.read_json(os.path.join(work_dir, \"by_date\", file_path), orient=\"index\")\n\n        for index, row in df.iloc[0:].iterrows():\n            status = row['Status']\n            latitude = row['Lattitude']\n            longitude = row['Longitude']\n            title = row['Title']\n            text = row['Text']\n            \n            icon_text=''\n            icon_size=''\n\n            if \"tweet\" in status:\n                icon_text='&#128038;'   # Unicode for the bird emoji\n                icon_size=(100,100)\n                folium.Marker(\n                [latitude,longitude],\n                icon=DivIcon(\n                    icon_size=icon_size,\n                    icon_anchor=(0,0),\n                    html='<div style=\"font-size: 12pt\">%s</div>' % icon_text,\n                    ),\n                popup = text\n            ).add_to(m)\n\n            elif \"fire\" in status: #wildfire\n                icon_text='&#128293;'   # Unicode for fire emoji\n                icon_size=(30,30)\n                folium.Marker(\n                [latitude,longitude],\n                icon=DivIcon(\n                    icon_size=icon_size,\n                    icon_anchor=(0,0),\n                    html='<div style=\"font-size: 12pt\">%s</div>' % icon_text,\n                    ),\n                ).add_to(m)\n                \n\n# render the final output:\nm\n"})}),"\n",(0,n.jsx)(t.h4,{id:"the-output-should-be-interactive-and-have-dynamic-overlays",children:"The output should be interactive and have dynamic overlays:"}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"link text",src:a(3043).A+"",width:"2284",height:"896"})})]})}function u(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(c,{...e})}):c(e)}},3043:(e,t,a)=>{a.d(t,{A:()=>n});const n=a.p+"assets/images/2024-08-05-172627_hyprshot-f8fdb6c4c3d7576db310c5955630d3dd.png"},8453:(e,t,a)=>{a.d(t,{R:()=>s,x:()=>d});var n=a(6540);const i={},o=n.createContext(i);function s(e){const t=n.useContext(o);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function d(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),n.createElement(o.Provider,{value:t},e.children)}}}]);